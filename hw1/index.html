<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}

			table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
            border: 1px solid black;
        }
        th, td {
            border: 1px solid black;
            padding: 8px;
            text-align: left;
        }

		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Swetha Rajkumar and Inas Zulaikha Anwar</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-swetha-inas-1/">https://cal-cs184-student.github.io/hw-webpages-swetha-inas-1/</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-swetha-inas/">https://github.com/cal-cs184-student/sp25-hw1-swetha-inas/</a>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>

		In this homework assignment, we implemented single-color triangle rasterization, supersampling, transformation functions, multi-colored triangle interpolation using barycentric coordinates, and texture mapping with pixel sampling and mipmap-based level sampling. We learned how rasterization is used in computer graphics to assign values from a continuous scene to individual pixels. We also learned about the significance of supersampling and how it can be used to improve the quality of images by reducing aliasing artifacts. Additionally, we learned about how pixel sampling and level sampling can be used to apply textures to objects in a scene. We implemented two different types of pixel sampling techniques, nearest and bilinear sampling, and used them to assign a pixel in screen space to the correct texture color in texture space. Finally, we implemented level sampling with mipmaps to select the appropriate resolution level of a texture when rendering a particular scene.

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		We rasterize triangles by iterating through every pixel within the triangle's bounding box and assigning it a specific color in the framebuffer based on whether it lies inside the triangle. Any pixel outside the bounding box is automatically considered outside the triangle, so its default white color in the framebuffer remains unchanged. To determine if a pixel is inside the triangle, we perform three line tests. For each test, we compute a line equation using a pair of triangle vertices and evaluate it at the pixel's center. We then multiply this result, <i>Li(x,y)</i>, by <i>winding</i>, which represents the triangle's winding order (positive for counterclockwise order and negative for clockwise). If this computation yields a value less than zero for any of the three line tests, we consider the pixel to be outside the triangle. On the other hand, if this computation yields a value that is greater than or equal to zero for all three line tests, then the pixel is inside the triangle. If the pixel is inside the triangle, we assign it the color specified by the function argument in the framebuffer. Otherwise, we leave its default white color in the framebuffer unchanged.
		<p></p>
		
		We determine the bounds of the triangle's bounding box using the minimum and maximum x and y coordinates among the three vertices of the triangle. The top-left corner of the bounding box is (min x vertex coordinate, min y vertex coordinate), and the bottom-right corner is (max x vertex coordinate, max y vertex coordinate). This bounding box is the smallest rectangle that fully encloses the triangle as it ensures that at a minimum, all its vertices are contained within it. By definition, if all vertices lie within the bounding box, then all pixels inside the triangle must also be within it. Therefore, it is sufficient to check only the pixel samples within this bounding box, and that is how our rasterization algorithm is implemented.

		<p></p>

		<figure>
			<img src="task_1.png" alt="single color triangle" style="width:50%"/>
			<figcaption>test4.svg</figcaption>
		</figure>

		<p>From the pixel inspector above, we can see that the red triangle has a lot of jaggies when using a supersample rate of 1 per pixel.</p>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		Supersampling is an approximation of 1-pixel box sampling and is useful for enabling anti-aliasing, which limits the effects of certain sampling artifacts like jaggies, false motion, and Moire. By taking multiple samples per pixel and averaging their color values, supersampling ensures the inclusion of intermediate colors, resulting in smoother transitions between pixels inside and outside the triangle and smoother edges overall. First, we resize the sample buffer to be of size <i>width * height * sample_rate</i> instead of size <i>width * height</i>. This follows from the idea that with supersampling, we now sample <i>sample_rate</i> times per pixel, so the sample buffer should store <i>sample_rate</i> color values for each pixel. After resizing and clearing the buffer each time the sample rate changes (to facilitate redrawing the scene when the sample rate is increased or decreased), we implement the supersampling algorithm. Similar to Task 1, we only check pixels within the triangle's bounding box. However, now we now perform our three line tests at the granularity of one sample rather than one pixel. We first take the square root of <i>sample_rate</i> to determine the number of samples to take in each direction (denoted as <i>num_blocks</i>), and calculate the block size (<i>block_size</i>) as <i>1/num_blocks</i>. Given these values, for each pixel, we iterate <i>num_blocks</i> times in both the x-direction (denoted as <i>i</i>) and the y-direction (denoted as <i>j</i>), calculating the center of each sample as <i>(x + block_size * (i + 0.5), y + block_size * (j + 0.5))</i> . We then check if this sample center is inside the triangle. If so, we set the value of the color at index <i>(y * width + x) * sample_rate + i * num_blocks + j</i> in the sample buffer to be the color specified by the function argument. Otherwise, we leave the color in the sample buffer at that index unchanged, letting it default to white. After filling the sample buffer, we modify the <i>resolve_to_framebuffer</i> function to average the <i>sample_rate</i> color values for each pixel and write the averaged red, green, and blue values to the framebuffer. This averaging allows the pixels to take intermediate color values, smoothing the edges. Additionally, we modify <i>fill_pixel</i> to store the same color for all supersamples of a pixel in the framebuffer, which is used for rasterizing points and lines.
		<p></p>
        In the table below, we can see that as the sample rate increases, the pixels can take on more intermediate values between red and white, creating a blurring effect that smooths the edges of the red triangle and eliminates sharp jaggies in the image. This effect becomes more noticeable where there are sharp transitions, such as at the corners of the skinny red triangle, which can be seen more clearly in the pixel inspectors for each of the three sampling rates.
		<p></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="task2_1.png" width="400px"/>
				  <figcaption>Sample Rate: 1</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="task2_2.png" width="400px"/>
				  <figcaption>Sample Rate: 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="task2_3.png" width="400px"/>
				  <figcaption>Sample Rate: 16</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 3: Transforms</h2>
		We wanted to make the cubeman perform a split jump, so we rotated its left and right legs by 60 degrees in the counterclockwise and clockwise directions respectively. To ensure proper alignment, we translated the left and right leg blocks by (-90, 70) and (90, 70), respectively. To give the cubeman a purple appearance, we filled the polygons with different shades: #C3B2C4 for the torso, #BFADC1 for the head, and #9B7F9D for the arms and legs.
		<figure>
			<img src="my_robot.png" alt="my robot" style="width:50%"/>
			<figcaption>Cubeman doing splits!</figcaption>
		</figure>

		<h2>Task 4: Barycentric coordinates</h2>
		Barycentric coordinates provide a coordinate system for triangles, allowing for the interpolation of values across the triangle's surface. Interpolation enables smooth variation of values across the triangle based on the values at its vertices. These interpolated values can include positions, texture coordinates, colors, and more. 
		
		<figure>
			<img src="task4_triangle.png" alt="triangle" style="width:50%"/>
			<figcaption>Smoothly blended color triangle.</figcaption>
		</figure>

		For example, the image above was generated using an svg file that plots a single triangle with one red, one green, and one blue vertex. Using barycentric coordinates to linearly interpolate the color values across the triangle, we obtained a smooth gradient of colors across its 2D surface.

		<p></p>

		For Task 4, our algorithm works as follows: We iterate through each sample (similar to Task 2) and compute &alpha;, &beta;, and &gamma; for the center of each sample using the following formula: 

		<p></p>

		<figure>
			<img src="bary_eqn.png" alt="barycentric formula" style="width:50%"/>
			<figcaption> </figcaption>
		</figure>

        If &alpha;, &beta;, and &gamma; are all nonnegative, we know that the sample center is inside the triangle, therefore we use the barycentric coordinates to compute the weighted average of the color values at the vertices as <i>newColor = &alpha; * c0 + &beta; * c1 + &gamma; * c2</i> and assign this resulting color to the sample buffer. 
		
		<p></p>

        Some downstream applications of barycentric coordinates include linear interpolation across a triangle, texture mapping (interpolating u/v coordinates to determine the appropriate texture for a pixel), calculating proportional areas and distances, and determining whether a point lies inside a triangle.	
        
		<p>Below is a color wheel generated using barycentric coordinates with default viewing parameters and a sample rate of 1.</p>

		<figure>
			<img src="task4_test7.png" alt="color wheel" style="width:50%"/>
			<figcaption>test7.svg: Color Wheel</figcaption>
		</figure>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		Pixel sampling is used for texture mapping, which is the task of assigning a pixel in screen space to the correct texture color in texture space. We first convert the screen space coordinates to u/v coordinates, and then apply one of two different pixel sampling methods (nearest and bilinear) to determine the texture color at the calculated u/v coordinates. The color of the pixel in screen space is then set to the corresponding texture color.

		<p>Our algorithm leverages the algorithm from Task 4, where we iterate through each sample and compute &alpha;, &beta;, and &gamma; for the center of each sample. If &alpha;, &beta;, and &gamma; are all nonnegative, we know that the sample center is inside the triangle. In this case, we use the barycentric coordinates to compute a weighted average of the u/v values at the vertices to get the sample's u/v coordinates as follows: </p>
		<p></p>
		<i>new_u = &alpha; * u0 + &beta; * u1 + &gamma; * u2</i>
		<p></p>
        <i>new_v = &alpha; * v0 + &beta; * v1 + &gamma; * v2</i>
		<p> Using these u/v coordinates and the level 0 mipmap, we can apply either nearest or bilinear sampling to determine the correct texture to apply. For nearest sampling, we return the color of the texel closest to the calculated u/v coordinates, and that is the color that is assigned to the sample in the sample buffer. For bilinear sampling, we identify the four closest texels to the u/v coordinates, and then perform linear interpolation in both the x and y directions to effectively compute a weighted average of the four texel colors. The resulting color is assigned to the sample in the sample buffer. </p>
		<p>Below are images of the UC Berkeley seal using nearest sampling at 1 sample per pixel, nearest sampling at 16 samples per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel. The image of the seal using nearest sampling appears more pixelated, which is especially noticeable in the letter "N" in "UNIVERSITY." The sharp changes in pixel color make the character harder to decipher. In contrast, the image of the seal with bilinear sampling appears more blended, with smoother transitions between pixel colors, making the same "N" clearer. Supersampling with nearest sampling reduces pixelation to some extent, but supersampling with bilinear sampling produces an even smoother texture. Bilinear sampling minimizes pixelation by creating smoother transitions between texture colors through bilinear interpolation. This method assigns a pixel's color in screen space by averaging the colors of the four nearest texels in u/v space. As the image is magnified and sharp color transitions (high frequencies) become more prominent, pixelation from nearest sampling becomes more noticeable, whereas bilinear sampling produces smoother color gradients.</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="nearest_1.png" width="400px"/>
				  <figcaption>Nearest Sampling, 1 Sample Per Pixel</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="nearest_16.png" width="400px"/>
				  <figcaption>Nearest Sampling, 16 Sample Per Pixel</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="bilinear_1.png" width="400px"/>
				  <figcaption>Bilinear Sampling, 1 Sample Per Pixel</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="bilinear_16.png" width="400px"/>
				  <figcaption>Bilinear Sampling, 16 Sample Per Pixel</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		Level sampling is used to select the appropriate resolution level of a texture when rendering a given scene. Each mipmap level corresponds to a different texture resolution, with higher levels corresponding to lower resolutions of the original texture. The system determines which mipmap level to sample from by estimating the texture footprint using the texture coordinates of neighboring screen samples. Some common level sampling methods include nearest level sampling, trilinear filtering (which blends between two adjacent mipmap levels), and anisotropic filtering (which applies an elliptical weighted average to reduce blurriness and distortion).

		<p>In our project, we implemented three types of level sampling. First, when <i>lsm == L_ZERO</i>, the texture is sampled from the highest resolution mipmap level. Next, <i>L_NEAREST</i> computes the nearest appropriate mipmap level and samples from it. Finally, <i>L_LINEAR</i> computes a continuous mipmap level and performs linear interpolation between the samples of the two closest mipmap levels. This corresponds to trilinear filtering, as described earlier. Depending on the <i>psm</i> value, we obtain samples either through nearest sampling or bilinear sampling.</p>

		<p>To implement level sampling in Task 6, we computed barycentric coordinates for the texture coordinates at three sample locations: <i>(x,y), (x+1,y), and (x,y+1)</i>. These values were stored in a <i>SampleParams</i> struct and passed into <i>Texture::sample(sp)</i>, which called <i>Texture::get_level(sp)</i> to determine the appropriate mipmap <i>level</i> to sample from. Our algorithm for <i>Texture::get_level(sp)</i> was implemented as follows: First, we computed the difference vectors <i>sp.p_dx_uv - sp.p_uv</i> and <i>sp.p_dy_uv - sp.p_uv</i> and scaled them by the width and height of the full-resolution texture image to obtain <i>du/dx, dv/dx, du/dy, and dv/dy</i>. Next, we computed <i>L</i> and <i>D</i> using the following equations:</p>

		<figure>
			<img src="d_eqn.png" alt="D and L equations" style="width:50%"/>
			<figcaption> </figcaption>
		</figure>

		<p>For <i>L_ZERO</i>, our <i>Texture::get_level(sp)</i> simply returned 0. For <i>L_NEAREST</i>, we rounded <i>D</i> to the nearest integer and returned that value. For <i>L_LINEAR</i>, we returned <i>D</i> as the float value we computed.</p>

		<p>After obtaining the appropriate mipmap level to sample from, our <i>Texture::sample(sp)</i> was implemented as follows: If <i>lsm</i> was not <i>L_LINEAR</i> and <i>psm</i> was <i>P_NEAREST</i>, we called <i>Texture::sample_nearest</i> with the <i>p_uv</i> value from the <i>sp</i> struct and the <i>level</i> converted to an integer, then returned the resulting sample. Similarly, if <i>lsm</i> was not <i>L_LINEAR</i> and <i>psm</i> was <i>P_LINEAR</i>, we called <i>Texture::sample_bilinear</i> with the <i>p_uv value</i> from the <i>sp</i> struct and the <i>level</i> converted to an integer, then returned the resulting sample. Finally, for <i>lsm == L_LINEAR</i>, we called either <i>Texture::sample_nearest</i> or <i>Texture::sample_bilinear</i> for both the floor and ceiling of the returned <i>level</i> depending on the value of <i>psm</i>. We then interpolated between these two samples and returned the final result.</p>

		<p>When comparing pixel sampling, level sampling, and supersampling (which adjusts the number of samples per pixel), we observe that in terms of speed, pixel sampling is the fastest, supersampling is the slowest, and level sampling falls in between. This is because pixel sampling only requires checking a fixed number of texels at the highest resolution, which is a fast computation. In contrast, level sampling incurs additional overhead from constructing different mipmaps on top of performing a specific pixel sampling technique. However, once the mipmaps are built, level sampling performs similarly to pixel sampling. Supersampling on the other hand requires sampling multiple times per pixel each time an image is rendered, which is a much slower process.</p>

		<p>Pixel sampling requires the least memory as it only stores the highest-resolution texture image. Level sampling requires more memory because it stores multiple resolutions of the same texture. Supersampling also requires a significant amount of memory to store all the pixel samples in the sample buffer. The exact memory requirements for level sampling and supersampling depend on the number of mipmap levels stored and the sampling rate.</p>

		<p>In terms of anti-aliasing effectiveness, supersampling is the most powerful as it samples pixels at a finer granularity which significantly reduces aliasing artifacts like jaggies. Level sampling is a close second, as it reduces pixelation by utilizing lower-resolution texture images to add more blurring. Pixel sampling has the least anti-aliasing power as it does not produce a lot of blurring or color continuity on its own. However, when combined with level sampling, it significantly improves the smoothness of edges and the blending of colors in the image.</p>

		<p>Below, we also provide speed, memory usage, and antialiasing power comparisons between different settings for each of the three techniques.</p>


		<h3>Level Sampling Method</h3>
    <table>
        <tr>
            <th>Level Sampling Method</th>
            <th>Speed</th>
            <th>Memory Usage</th>
            <th>Antialiasing Power</th>
        </tr>
        <tr>
            <td>L_ZERO</td>
            <td>Fast - samples from the level 0 mipmap</td>
            <td>Low - only requires the full resolution texture image</td>
            <td>Low - aliasing artifacts are clearly visible</td>
        </tr>
        <tr>
            <td>L_NEAREST</td>
            <td>Fast - samples from the nearest mipmap level</td>
            <td>High - requires storage of the texture at several resolution levels</td>
            <td>Average - adds more blurring and reduces pixelation</td>
        </tr>
        <tr>
            <td>L_LINEAR</td>
            <td>Fairly fast - samples from two different mipmap levels and interpolates these values</td>
            <td>High - requires storage of the texture at several resolution levels</td>
            <td>High - smoother color transitions in the image</td>
        </tr>
    </table>

    <h3>Pixel Sampling Method</h3>
    <table>
        <tr>
            <th>Pixel Sampling Method</th>
            <th>Speed</th>
            <th>Memory Usage</th>
            <th>Antialiasing Power</th>
        </tr>
        <tr>
            <td>P_NEAREST</td>
            <td>Fast - returns the color of the nearest texel</td>
            <td>Low - accesses a constant number of texels (1)</td>
            <td>Low - image is very pixelated</td>
        </tr>
        <tr>
            <td>P_LINEAR</td>
            <td>Fairly fast - computes a weighted average of the four closest texel colors</td>
            <td>Low - accesses a constant number of texels (4)</td>
            <td>High - smoother transitions between different colors</td>
        </tr>
    </table>

    <h3>Sampling Rate</h3>
    <table>
        <tr>
            <th>Sampling Rate</th>
            <th>Speed</th>
            <th>Memory Usage</th>
            <th>Antialiasing Power</th>
        </tr>
        <tr>
            <td>1 per pixel</td>
            <td>Fast - only 1 sample is evaluated per pixel</td>
            <td>Low - only one color needs to be stored for each pixel</td>
            <td>Low - jaggies and other aliasing artifacts are clearly visible</td>
        </tr>
        <tr>
            <td>4 per pixel</td>
            <td>Average - 4 samples are evaluated per pixel</td>
            <td>Average - four colors need to be stored for each pixel</td>
            <td>Average - adds more blurring to the image</td>
        </tr>
        <tr>
            <td>9, 16, and more per pixel</td>
            <td>Slow - many samples are evaluated per pixel</td>
            <td>High - many more colors need to be stored for each pixel</td>
            <td>High - smoother color transitions and blending in the image</td>
        </tr>
    </table>
	<p></p>
	<p>Below are four versions of our chosen image (UC Berkeley view) using different level sampling and pixel sampling combinations. We observed that with <i>L_ZERO</i> and <i>P_NEAREST</i>, the image appears highly pixelated as it uses the full-resolution image with nearest sampling, as seen in the view of a part of the bridge in the pixel inspector. When switching to <i>L_ZERO</i> and <i>P_LINEAR</i>, we noticed that while the shades of some individual pixels changed, there wasn't a significant difference in the overall image. This is because <i>L_ZERO</i> prevents the pixels from taking on many intermediate values, which limits the effect of the averaging done by <i>P_LINEAR</i>. The pixel inspector confirms this, as there is still noticeable pixelation on the bridge. With <i>L_NEAREST</i> and <i>P_NEAREST</i>, we start to see more blurring, as we are now sampling from a lower-resolution texture map, although some pixelation still remains. The pixel inspector shows that the bridge cables are completely blurred, which results from applying the lower-resolution texture. Finally, with <i>L_NEAREST</i> and <i>P_LINEAR</i>, the image becomes fully smoothed. In the pixel inspector, we can now see that the colors of the sky and bridge are more blended with each other.</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="task6_1.png" width="400px"/>
				  <figcaption>L_ZERO, P_NEAREST</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="task6_2.png" width="400px"/>
				  <figcaption>L_ZERO, P_LINEAR</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="task6_3.png" width="400px"/>
				  <figcaption>L_NEAREST, P_NEAREST</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="task6_4.png" width="400px"/>
				  <figcaption>L_NEAREST, P_LINEAR</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		</div>
	</body>
</html>