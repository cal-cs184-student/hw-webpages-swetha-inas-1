<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Inas Zulaikha Anwar and Swetha Rajkumar</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-swetha-inas-1/">https://cal-cs184-student.github.io/hw-webpages-swetha-inas-1/</a>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-swetha-and-inas.git">https://github.com/cal-cs184-student/sp25-hw3-swetha-and-inas.git</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
	<p>In this project, we built a renderer to produce realistic images using a path tracing algorithm. We began by implementing ray generation and scene intersection, which involved converting coordinates from image space to camera space, generating pixel samples, and coding ray-triangle and ray-sphere intersection tests. We realized that even with basic shading, renders were slow. We implemented a Bounding Volume Hierarchy (BVH) to accelerate rendering and implemented intersection tests for bounding boxes and the BVH itself.</p>

		<p>We also added direct illumination features, including a diffuse Bidirectional Scattering Distribution Function (BSDF), zero-bounce illumination (light reaching the camera directly), and direct lighting using both uniform hemisphere sampling and importance sampling of lights. We then added global illumination to further smooth renders, using recursive path tracing to estimate incoming light and Russian Roulette for unbiased termination.</p>
		
	<p>Finally, we implemented adaptive sampling to reduce image noise by dynamically allocating more samples to regions that require better precision at the cost of an increased render time. Upon completion, we have a deeper appreciation for the complexity behind photorealistic computer-generated imagery.</p>
		
		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<p><b>Ray generation and primitive intersection parts of the rendering pipeline:</b></p>

		<p>The <b>Camera::generate_ray(...) function</b> begins by converting <b>hFov</b> and <b>vFov</b> from radians to degrees. Next, we construct a transformation matrix to map points from image space to camera space: <b>[2 * tan(0.5 * hFov_rad) 0 -tan(0.5 * hFov_rad) 0 2 * tan(0.5 * vFov_rad) -tan(0.5 * vFov_rad) 0 0 1]</b>. This matrix is derived from the fact that its columns must include the u and v vectors along the camera space plane as well as the origin of the camera space plane. Since all points in camera space have a z coordinate of -1, we explicitly set this value after performing the 2D transformation of the normalized <b>x</b> and <b>y</b> coordinates. Next, we construct a ray in camera space using the transformed coordinates and the camera origin. We then apply the <b>c2w</b> transformation to convert both the origin and direction into world space, effectively generating a ray in world space. Finally, we initialize the ray's <b>min_t</b> and <b>max_t</b> values to <b>nClip</b> and <b>fClip</b>, respectively, and return the constructed ray.</p>

		<p>Next, we implemented <b>PathTracer::raytrace_pixel(...)</b>, which calls <b>PathTracer::est_radiance_global_illumination(...)</b> to estimate the integral of radiance over a specific pixel coordinate. This is done by averaging <b>ns_aa</b> samples and updating the <b>sampleBuffer</b> at that pixel location with the computed radiance integral. To achieve this, we called <b>gridSampler->get_sample()</b> <b>ns_aa</b> times. In each iteration, we added the <b>x</b> and <b>y</b> coordinates of the sample vector to the input <b>x</b> and <b>y</b>, then normalized them by <b>sampleBuffer.w</b> and <b>sampleBuffer.h</b>. These normalized coordinates were passed to <b>generate_ray()</b> to obtain a ray in world space, which was then passed to <b>est_radiance_global_illumination(...)</b> to estimate the scene radiance along the ray. Finally, we averaged the scene radiance from all <b>ns_aa</b> rays to estimate the integral of radiance over the pixel.</p>

        <p>We also implemented functions to detect and determine the point(s) of intersection for the triangle and sphere primitives. These are described in more detail below. </p>

		<p><b>The triangle intersection algorithm we implemented:</b></p>

		<p>For triangle intersection, we used the concept that any point inside a triangle with vertices <b>p1</b>, <b>p2</b>, and <b>p3</b> can be represented using barycentric coordinates: <b>(1 - b1 - b2, b1, b2)</b>. We set this point, <b>p1 * (1 - b1 - b2) + p2 * b1 + p3 * b2</b> equal to the ray equation: <b>r(t) = o + t * d</b></p>

		<p>By collecting terms and rewriting the equation in matrix form, we solved for <b>t</b>, <b>b1</b>, and <b>b2</b> by multiplying the inverse of the matrix <b>[-r.d, p2 - p1, p3 - p1]</b> with <b>r.o - p1</b>.</p>

		<p>Here, <b>t</b> represents the intersection time, while <b>b1</b> and <b>b2</b> are the barycentric coordinates corresponding to <b>p2</b> and <b>p3</b>, respectively, which define the intersection point within the triangle. The barycentric coordinate corresponding to <b>p1</b> is given by <b>1 - b1 - b2.</b></p>

		<p>To determine whether an intersection occurs, we check if the following condition holds:</p>
		<p><b>
			sol.x >= r.min_t && sol.x <= r.max_t &&
			1 - sol.y - sol.z >= 0 && 1 - sol.y - sol.z <= 1 &&
			sol.y >= 0 && sol.y <= 1 && sol.z >= 0 && sol.z <= 1;
		</b></p>
	
		<p>where <b>sol.x</b> represents <b>t</b>, <b>sol.y</b> represents <b>b1</b>, and <b>sol.z</b> represents <b>b2</b>.</p>

		In <b>has_intersection()</b>, if the condition is satisfied, we return <b>true</b>; otherwise, we return <b>false</b>.
        In <b>intersect()</b>, if the condition is met, we return <b>true</b> and update the intersection information as follows:
		<ul>
			<li><strong>isect->t = sol.x;</strong></li>
			<li><strong>r.max_t = sol.x;</strong></li>
			<li><strong>isect->bsdf = get_bsdf();</strong></li>
			<li><strong>isect->primitive = this;</strong></li>
			<li><strong>isect->n = (1 - sol.y - sol.z) * n1 + sol.y * n2 + sol.z * n3;</strong></li>
		</ul>
		<p>Otherwise, we simply return <b>false</b>.</p>

		<p><b>The sphere intersection algorithm we implemented:</b></p>

		<p>For sphere intersection, we followed a similar approach in <strong>Sphere::test(...)</strong>. We used the equation for a sphere: <strong>(p - o) ^ 2 - r2 = 0</strong></p>
		<p>Substituting <strong>p</strong> with the ray equation <strong>r(t) = o + t * d</strong>, we solved for the intersection times <strong>t</strong> using the quadratic formula, where:</p>
		<ul>
			<li><strong>a = dot(r.d, r.d)</strong></li>
			<li><strong>b = 2 * dot(r.o - o, r.d)</strong></li>
			<li><strong>c = dot(r.o - o, r.o - o) - r2</strong></li>
		</ul>
		<p>If <strong>bÂ² - 4ac</strong> was negative or if both intersection times were either less than <strong>r.min_t</strong> or greater than <strong>r.max_t</strong>, we returned <strong>false</strong>. Otherwise, we computed the minimum of the two intersection times (<strong>t1</strong>) and the maximum (<strong>t2</strong>), returning <strong>true</strong>.</p>
		
		<p>The <strong>Sphere::has_intersection(...)</strong> function simply returns the boolean result from <strong>Sphere::test(...)</strong>.</p>
	
		<p>Meanwhile, <strong>Sphere::intersect(...)</strong> also performs the following assignments if at least one intersection occurs before returning the boolean value from <strong>Sphere::test(...)</strong>:</p>
	
		<ul>
			<li><strong>i->t = t1;</strong></li>
			<li><strong>if (t1 &lt; r.min_t &amp;&amp; t1 &gt; r.max_t) { i->t = t2; }</strong></li>
			<li><strong>r.max_t = i->t;</strong></li>
			<li><strong>Vector3D normal_vec = r.at_time(i->t) - o;</strong></li>
			<li><strong>normal_vec.normalize();</strong></li>
			<li><strong>i->n = normal_vec;</strong></li>
			<li><strong>i->primitive = this;</strong></li>
			<li><strong>i->bsdf = get_bsdf();</strong></li>
		</ul>	


		<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>

		<p><b>Our BVH construction algorithm and the heuristic we chose for picking the splitting point:</b></p>
		
		<p>
			In the <b>BVHAccel::construct_bvh()</b> function, we used the provided start and end iterators to gather the bounding boxes of all the primitive shapes and create a new bounding box (<b>bbox</b>) that encapsulates all these bounding boxes. We also created a new vector, <b>std::vector&lt;Primitive *&gt; primitive_shapes</b>, to store the individual primitives while iterating through them using the start and end iterators.
		</p>
		
		<p>
			Next, we constructed a new <b>BVHNode</b> using <b>bbox</b>. We then checked if the size of the <b>primitive_shapes</b> vector was less than or equal to the <b>max_leaf_size</b>. If it was, we assigned <b>node-&gt;start</b> and <b>node-&gt;end</b> the same values that were passed to <b>BVHAccel::construct_bvh()</b> and returned the node.
		</p>
		
		<p>
			If the size of <b>primitive_shapes</b> exceeded the <b>max_leaf_size</b>, we determined the longest axis of the bounding box (x, y, or z) and split along that axis. The split point was calculated as the average of the centroids along the longest axis. After determining the split point, we divided the primitives into two vectorsâ<b>std::vector&lt;Primitive *&gt; *leftprimitives</b> and <b>std::vector&lt;Primitive *&gt; *rightprimitives</b>âbased on whether their centroid coordinate along the longest axis was less than or greater than or equal to the average.
		</p>
		
		<p>
			Finally, we recursively called <b>BVHAccel::construct_bvh()</b> on the beginning and end of <b>leftprimitives</b> and <b>rightprimitives</b> with the same <b>max_leaf_size</b>, assigning the results to <b>node-&gt;l</b> and <b>node-&gt;r</b> respectively. After the recursion, we returned the node.
		</p>
		

		<h2>Part 3: Direct Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 4: Global Illumination</h2>
		<p><b>Our implementation of the indirect lighting function:</b></p>

		<p>We added support for indirect lighting on top of our direct lighting function to consider light reflected from other surfaces within the scene. In <i>est_radiance_global_illumination()</i>, we first call <i>zero_bounce_radiance()</i> and then call <i>at_least_one_bounce_radiance()</i> and add the result of it.</p>

		<p>We begin by calling <i>one_bounce_radiance()</i> to calculate the direct lighting at the current ray and intersection point. If the ray's depth is 1 or less, we stop the process. Otherwise, we continue. We use a fixed continuation probability (cpdf) to perform Russian Roulette, which may terminate the function early with probability 1 - cpdf. If the function continues, we compute the next ray bounce. A BSDF value is sampled at the surface intersection using <i>isect->bsdf.sample_f()</i>, and a new ray and intersection point are generated, with the new rayâs depth reduced by one. We then check for an intersection with the BVH. If an intersection occurs, we recursively call <i>at_least_one_bounce_radiance()</i> with the new ray, apply the reflectance formula to the result, and add it to the total indirect lighting. We end by returning the accumulated indirect illumination.</p>

		<p><b>Images rendered with global (direct and indirect) illumination:</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="4_spheres_global.png" width="400px"/>
		<figcaption><i>spheres</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="4_blob_global.png" width="400px"/>
						<figcaption><i>blob.dae</i></figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p><b>Comparing rendered views with only direct illumination and indirect illumination:</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="4_spheres_direct.png" width="400px"/>
		<figcaption><i>with only direct illumination</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="4_spheres_indirect.png" width="400px"/>
						<figcaption><i>with only indirect illumination</i></figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p><b>Rendering the mth bounce of light for <i>CBbunny.dae</i> with <i>max_ray_depth</i> set to 0, 1, 2, 3, 4, and 5 (the -m flag), and <i>isAccumBounces=false</i>:</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="bounce0.png" width="400px"/>
		<figcaption><i>max_ray_depth = 0</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce1.png" width="400px"/>
						<figcaption><i>max_ray_depth = 1</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bounce1test.png" width="400px"/>
		<figcaption><i>max_ray_depth = 2</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce2test.png" width="400px"/>
						<figcaption><i>max_ray_depth = 3</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bounce3test.png" width="400px"/>
		<figcaption><i>max_ray_depth = 4</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce4test.png" width="400px"/>
						<figcaption><i>max_ray_depth = 5</i></figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p><b>What we see for the 2nd and 3rd bounce of light and how it contributes to the quality of the rendered image compared to rasterization:</b></p>

		<p>The 2nd and 3rd bounces of light create a softer and more natural-looking result. This is because in path tracing, it accounts for factors like light bouncing, energy conservation, and color spill surfaces. In comparison to rasterization, it produces more accurate photos without the extra approximations.</p>

		<p><b>Rendered views of accumulated and unaccumulated bounces for <i>CBbunny.dae</i> with <i>max_ray_depth</i> set to 0, 1, 2, 3, 4, and 5 (the -m flag):</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="bounce0.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 0</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce0.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 0</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bunny_true_1.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 1</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce1.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 1</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bunny_true_2.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 2</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce1test.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 2</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="cb_bunny_m3_accum.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 3</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce2test.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 3</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="cb_bunny_m2_accum.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 4</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce3test.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 4</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="cb_bunny_m1_accum.png" width="400px"/>
		<figcaption><i>Accumulated bounces with m = 5</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bounce4test.png" width="400px"/>
						<figcaption><i>Unaccumulated bounces with m = 5</i></figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p><b>Outputting Russian Roulette rendering with different max_ray_depths and 1024 samples per pixel:</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="bunny_m0.png" width="400px"/>
		<figcaption><i>max_ray_depth = 0</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bunny_m1.png" width="400px"/>
						<figcaption><i>max_ray_depth = 1</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bunny_m2.png" width="400px"/>
		<figcaption><i>max_ray_depth = 2</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bunny_m3.png" width="400px"/>
						<figcaption><i>max_ray_depth = 3</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="bunny_m4.png" width="400px"/>
		<figcaption><i>max_ray_depth = 4</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bunny_m100.png" width="400px"/>
						<figcaption><i>max_ray_depth = 100</i></figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p><b>Comparing rendered views of <i>CBspheres_lambertian.dae</i>with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024, using 4 light rays:</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="spheres_s1.png" width="400px"/>
		<figcaption><i>s = 1</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_s2.png" width="400px"/>
						<figcaption><i>s = 2</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="spheres_s4.png" width="400px"/>
		<figcaption><i>s = 4</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_s8.png" width="400px"/>
						<figcaption><i>s = 8</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="spheres_s16.png" width="400px"/>
		<figcaption><i>s = 16</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_s32.png" width="400px"/>
						<figcaption><i>s = 32</i></figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="spheres_s64.png" width="400px"/>
		<figcaption><i>s = 64</i></figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_s1024.png" width="400px"/>
						<figcaption><i>s = 1024</i></figcaption>
					</td>
				</tr>
			</table>
		</div>
		

		<h2>Part 5: Adaptive Sampling</h2>

		<p><b>Adaptive sampling and our implementation of it:</b></p>

		<p>From what we observe, Monte Carlo path tracing is effective for producing realistic images, but it often introduces significant noise. While increasing the number of samples per pixel can help reduce this noise, itâs not the most efficient approach. Adaptive sampling offers a more optimized solution by adjusting the sampling rate based on how quickly each pixel converges. This method avoids uniformly oversampling all pixels and instead allocates fewer samples to pixels that converge quickly and more to those in complex regions of the image.</p>

		<p>To implement this, we modified the <i>raytrace_pixel()</i> function with a simple adaptive sampling algorithm. We start by initializing two variables, s1 and s2, to zero. As we loop through the samples, we calculate the illuminance of each one and update s1 and s2 with the cumulative illuminance and the square of the illuminance, respectively. At regular intervals (every <i>samplesPerBatch</i> iterations), we compute the mean and standard deviation using these values. By dividing the standard deviation by the number of samples taken so far, we estimate how much the pixel has converged. If this value is less than or equal to <i>maxTolerance</i> multiplied by the mean, we consider the pixel converged and stop sampling early. If not, we continue sampling as usual.</p>

		<p><b>Task: Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.</b></p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		<table style="width: 100%; text-align: center; border-collapse: collapse;">
		<tr>
					<td style="text-align: center;">
						<img src="bunny_task5.png" width="400px"/>
		<figcaption>Rendered Image</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="bunny_task5_rate.png" width="400px"/>
						<figcaption>Sample Rate Image</figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="spheres_task5.png" width="400px"/>
		<figcaption>Rendered Image</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="spheres_task5_rate.png" width="400px"/>
						<figcaption>Sample Rate Image</figcaption>
					</td>
				</tr>
		<tr>
					<td style="text-align: center;">
						<img src="dragon_task5.png" width="400px"/>
		<figcaption>Rendered Image</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="dragon_task5_rate.png" width="400px"/>
						<figcaption>Sample Rate Image</figcaption>
					</td>
				</tr>
			</table>
		</div>


		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>